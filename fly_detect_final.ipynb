{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros\n",
    "\n",
    "rect = 150\n",
    "\n",
    "# crea el dataframe\n",
    "\n",
    "drosophila = pd.DataFrame(columns=['id', 'pixels' ,'x', 'y', 'sex', 'state', 'targetX', 'targetY'])\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# incrementa el brillo de la imagen\n",
    "\n",
    "def increase_brightness(img, value = 30):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarizacion, br cantidad de brillo, gb = kernel del gaussian blur, li y ls limites superior e inferior del theadhold\n",
    "\n",
    "def image_threshold(img, br = 150, gb = 3, li = 230, ls= 255):\n",
    "    img_b = increase_brightness(img, value=br)\n",
    "    img_b  = cv2.cvtColor(img_b, cv2.COLOR_BGR2GRAY)\n",
    "    img_b = cv2.GaussianBlur(img_b, (gb,gb), 0)\n",
    "    _, img_c = cv2.threshold(img_b, li, ls, cv2.THRESH_BINARY)\n",
    "    return img_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological Operations: erosiona y dilata ... k tamano del kernel, d_iter, e_iter iteraciones en dilatacion y erosion\n",
    "\n",
    "def image_erodil(img, d_iter = 10, e_iter = 10, k = 3):\n",
    "    # erossion and dilatation\n",
    "    kernel = np.ones((k,k), np.uint8)\n",
    "\n",
    "    img = cv2.dilate(img, kernel, iterations = d_iter)\n",
    "    img = cv2.erode(img, kernel, iterations = e_iter)\n",
    "    return  img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_overlap(img, rect= 150, show = False):\n",
    "    \n",
    "        temp_cont, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        ret = 'sin clasificar'\n",
    "\n",
    "        if (len(temp_cont)>1):                      # cuenta contornos en temp_img\n",
    "            \n",
    "            ret = 'overlaped'\n",
    "\n",
    "            if show:                                # imprime superposición\n",
    "                plt.figure(figsize = (100,10))\n",
    "                plt.imshow(img)\n",
    "            \n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def img_classification(img):\n",
    "    sex = random.choice([\"f\", \"m\"])\n",
    "    return sex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_addBoundingbox(img, x0, y0, ov, text, q, y_text = 10, s = \"n/a\"):\n",
    "    c = (0,0,0)\n",
    "    if ov == \"sin clasificar\": c = (0,128,0)        # verde\n",
    "    if ov == \"overlaped\": c = (255,0,0)             # rojo\n",
    "    if ov == \"fuera umbral 1\": c = (0,0,0)          # negro\n",
    "    if ov == \"fuera umbral 2\": c = (255,255,0)        # marron\n",
    "    if ov == \"classified\": \n",
    "        if s == \"f\": c = (255,0,255)      # rosa\n",
    "        if s == \"m\": c = (0,0,255)        # azul\n",
    "    cv2.rectangle(img, (x0, y0), (x0+rect, y0+rect), c, 5)\n",
    "\n",
    "    if text:\n",
    "        cv2.putText(img, str(q), (x0, y0-y_text), font, 1, c, 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecta y analiza contornos, t? rect: tamanno del recuadro, pMin, pMax: % maximo y minimo de pixes ocupados\n",
    "\n",
    "def image_contours(img_t, img_o, drosophila, writePNG = False, t = 10, rect = 150, pMin = 4, pMax = 20):\n",
    "    img_t = cv2.bitwise_not(img_t)\n",
    "    contornos, _ = cv2.findContours(img_t, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img_fin = img_o.copy()\n",
    "\n",
    "    hmin = 20\n",
    "    wmin = 20\n",
    "    hmax = 120\n",
    "    wmax = 120\n",
    "    y_text = 10\n",
    "\n",
    "    cont = 0\n",
    "\n",
    "    for c in contornos:\n",
    "        if len(c)>t:                                # que carajos es t??? y este proc???\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(c)                          # realiza el bounding box\n",
    "\n",
    "            x0 = int((x + w/2) - (rect/2))                              # localiza la coordenada x0 basado en el tamaño del recuadro\n",
    "            y0 = int((y + h/2) - (rect/2))                              # localiza la coordenada y0 basado en el tamaño del recuadro\n",
    "            \n",
    "            cont = cont + 1                                             # incrementa la cantidad de objetos encontrados\n",
    "            \n",
    "            if ((h>hmin) and (w>wmin)) and ((h<hmax) and (w<wmax)):     # tamaño minimo y maximo del recuadro\n",
    "\n",
    "                roi1 = img_t[y0:y0+rect, x0:x0+rect]                    # roi de imagen binarizada\n",
    "                q = cv2.countNonZero(roi1)                              # calculo de % de pixels ocupados\n",
    "                p = round((q/(rect*rect))*100, 1)\n",
    "                \n",
    "                if (p>pMin) and (p<pMax):                               # seleccion de % minimo y maximo\n",
    "\n",
    "                    ov = image_overlap(roi1)                            # verifica superposición de imagenes\n",
    "                \n",
    "                    if writePNG:\n",
    "                        roi = img_o[y0:y0+rect, x0:x0+rect] \n",
    "                        cv2.imwrite(str(cont)+'.png', roi)\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    ov = \"fuera umbral 1\"\n",
    "                \n",
    "            else:\n",
    "\n",
    "                ov = \"fuera umbral 2\"\n",
    "            \n",
    "\n",
    "            img_fin = image_addBoundingbox(img_fin, x0, y0, ov, True, cont, y_text)\n",
    "\n",
    "            drosophila.loc[len(drosophila.index)] = [cont, p, x0, y0, \"n/a\", ov, 0, 0]   # registra el roi\n",
    "\n",
    "\n",
    "    return img_fin    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marca el centro de masa, cross tamaño de la mira\n",
    "\n",
    "def roi_target(roi, img, x0, y0, cross = 30):\n",
    "    \n",
    "    c = int(cross/2)                         #  la cruz tiene 2*cross de lado\n",
    "    \n",
    "    eyes_lo=np.array([90,60,60])\n",
    "    eyes_hi=np.array([125,85,85])\n",
    "\n",
    "    mask=cv2.inRange(roi, eyes_lo, eyes_hi)\n",
    "    M = cv2.moments(mask)\n",
    " \n",
    "\n",
    "    # calculate x,y coordinate of center\n",
    "    x = int(M[\"m10\"] / M[\"m00\"])\n",
    "    y = int(M[\"m01\"] / M[\"m00\"])\n",
    " \n",
    "    x = x0 + x\n",
    "    y = y0 + y\n",
    "\n",
    "    # put text and highlight the center\n",
    "    cv2.circle(img, (x, y), 5, (255, 255, 255), -1)\n",
    "    cv2.putText(img, \"target\", (x - 25, y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    " \n",
    "    \n",
    "\n",
    "    cv2.line(img, (x, y-c), (x, y+c), (255, 255, 0), 2) \n",
    "    cv2.line(img, (x-c, y), (x+c, y), (255, 255, 0), 2) \n",
    "\n",
    "    return x, y, img\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marca el centro de masa, cross tamaño de la mira (teniendo en cuenta que son boundingboxes con errores)\n",
    "\n",
    "def roi_target_plus(roi, img, x0, y0, cross = 30):\n",
    "\n",
    "    c = int(cross/2)                         #  la cruz tiene 2*cross de lado\n",
    "\n",
    "    roi = cv2.bitwise_not(roi)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    roi = cv2.erode(roi, kernel, iterations = 10)\n",
    "    contornos, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    for contor in contornos:\n",
    "        (x, y, w, h) = cv2.boundingRect(contor) \n",
    "        x = int(x + w/2) + x0\n",
    "        y = int(y + h/2) + y0\n",
    "\n",
    "        # put text and highlight the center\n",
    "        cv2.circle(img, (x, y), 5, (255, 255, 255), -1)\n",
    "        cv2.putText(img, \"target\", (x - 25, y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    " \n",
    "        cv2.line(img, (x, y-c), (x, y+c), (255, 255, 0), 2) \n",
    "        cv2.line(img, (x-c, y), (x+c, y), (255, 255, 0), 2) \n",
    "\n",
    "    return x, y, img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classification(img, img_de, drosophila, rect = 150):\n",
    "\n",
    "    # recorre el dataset de las que estan en estado \"sin clasificar\"\n",
    "\n",
    "    img_f = img.copy()\n",
    "\n",
    "    for _, row in drosophila.iterrows():\n",
    "\n",
    "        targetX = 0\n",
    "        targetY = 0\n",
    "\n",
    "        x0 = int(row.x)\n",
    "        y0 = int(row.y)\n",
    "\n",
    "        roi = img[y0:y0+rect, x0:x0+rect]  \n",
    "        st = row.state\n",
    "\n",
    "        s = 'n/a'\n",
    "        if (row.state == 'sin clasificar'):\n",
    "            s = img_classification(roi)                                                 # clasifica la mosca\n",
    "            st = 'classified'\n",
    "            \n",
    "\n",
    "        if (s==\"f\") and ((x0>0) and (y0>0)):\n",
    "            targetX, targetY, img_f = roi_target(roi, img, x0, y0, 30)                  # encuentra punto de target de moscas ok\n",
    "\n",
    "        if (st != \"classified\") and ((x0>0) and (y0>0)):\n",
    "            roi = img_de[y0:y0+rect, x0:x0+rect]  \n",
    "            targetX, targetY, img_f = roi_target_plus(roi, img, x0, y0, 30)                  # encuentra punto de target de moscas con problemas\n",
    "\n",
    "        # actualiza el dataframe\n",
    "        drosophila.loc[drosophila['id'] == row.id, ['state']] = st\n",
    "        drosophila.loc[drosophila['id'] == row.id, ['sex']] = s\n",
    "        drosophila.loc[drosophila['id'] == row.id, ['targetX']] = targetX\n",
    "        drosophila.loc[drosophila['id'] == row.id, ['targetY']] = targetY\n",
    "        \n",
    "\n",
    "        # redibuja boundingboxes\n",
    "        #if ((s==\"f\") or (s==\"m\")): \n",
    "        img_f = image_addBoundingbox(img_f, x0, y0, st, True, row.id, 10, s)\n",
    "\n",
    "    return img_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = cv2.imread('images/Fotos 1-11-097.jpeg', cv2.COLOR_BGR2RGB) \n",
    "img_orig = cv2.cvtColor(img_orig, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "img_pre = image_threshold(img_orig, 150, 3, 230, 255)\n",
    "img_de = image_erodil(img_pre, 10, 10, 3)\n",
    "\n",
    "plt.figure(figsize = (200,20))\n",
    "plt.imshow(img_de) \n",
    "\n",
    "img_c = image_contours(img_de, img_orig, drosophila, False)\n",
    "\n",
    "plt.figure(figsize = (200,20))\n",
    "plt.imshow(img_c) \n",
    "\n",
    "# clasifica, genera el target y el recorrido del laser en las que estan verde (sin clasificar)\n",
    "\n",
    "img_f = image_classification(img_orig, img_de, drosophila, rect = 150)\n",
    "\n",
    "plt.figure(figsize = (200,20))\n",
    "plt.imshow(img_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drosophila.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drosophila.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "laser_optRoute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    x0 = drosophila.at[_, \"x\"] \n",
    "    y0 = drosophila.at[_, \"y\"] \n",
    "    temp_img = img_erodil[y0:y0+rect, x0:x0+rect]\n",
    "    temp_cont, _ = cv2.findContours(temp_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # cuenta contornos en temp_img\n",
    "\n",
    "    if (len(temp_cont)>1):\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        print(row.id)\n",
    "\n",
    "        # imprime superposición\n",
    "        plt.figure(figsize = (100,10))\n",
    "        plt.imshow(temp_img)\n",
    "        cv2.rectangle(img_fin2, (x0, y0), (x0+rect, y0+rect), (255, 0, 0), 6)\n",
    "\n",
    "\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
